{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xoLDtS_6Df1"
      },
      "source": [
        "# 필작이의 chatbot\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP5EaMlIR9ZI",
        "outputId": "05d06784-77a7-46bb-b959-c287f3db519e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.32.0-py2.py3-none-any.whl (8.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.10.0)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.42 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.32.0 watchdog-4.0.0\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 2.254s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 1 \u001b[93mmoderate\u001b[0m severity vulnerability\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25hRequirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (4.10.0)\n"
          ]
        }
      ],
      "source": [
        "# openai, streamlit, localtunnel 설치\n",
        "!pip install openai==0.28\n",
        "!pip install streamlit\n",
        "!npm install localtunnel\n",
        "!pip install -U typing_extensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-Qvbrz8-7dn",
        "outputId": "4c2203be-b984-4dc5-eacc-b5d44c8d6b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting elastic_gpt_app.py\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "%%writefile elastic_gpt_app.py\n",
        "\n",
        "\n",
        "import os\n",
        "import streamlit as st\n",
        "import openai\n",
        "import json\n",
        "from elasticsearch import Elasticsearch\n",
        "\n",
        "#openai apy key 입력\n",
        "openai_api = ''\n",
        "\n",
        "\n",
        "openai.api_key = openai_api\n",
        "model = \"gpt-3.5-turbo-0301\"\n",
        "\n",
        "def es_connect(cid, user, passwd):\n",
        "    es = Elasticsearch(cloud_id=cid, http_auth=(user, passwd))\n",
        "    return es\n",
        "\n",
        "# Elasticsearch Search\n",
        "def search(query_text):\n",
        "    # ES Cloud ID, Username, Password 입력\n",
        "    cid = ''\n",
        "    cu = ''\n",
        "    cp = ''\n",
        "\n",
        "    es = es_connect(cid, cu, cp)\n",
        "\n",
        "    # 엘라스틱 검색\n",
        "    query = {\n",
        "        \"bool\": {\n",
        "          \"should\": [{\n",
        "            \"match\": {\n",
        "              \"EXPLAIN\": {\n",
        "                \"query\": query_text,\n",
        "                \"boost\": 50\n",
        "              }\n",
        "            }\n",
        "          },\n",
        "          {\n",
        "          \"match_phrase_prefix\": {\n",
        "            \"EXPLAIN\": {\n",
        "              \"query\": query_text,\n",
        "              \"boost\": 1\n",
        "            }\n",
        "          }\n",
        "          }\n",
        "      ],\n",
        "      \"filter\": [{\n",
        "        \"exists\": {\n",
        "          \"field\": \"EXPLAIN\"\n",
        "          }\n",
        "      }],\n",
        "            \"minimum_should_match\": 1\n",
        "        }\n",
        "    }\n",
        "    sort={\"_score\": {\"order\": \"desc\"}}\n",
        "    index = 'buildings_2'\n",
        "    fields = [\"CITY\", \"EXPLAIN\", \"ADDRESS\", \"THEME\", \"NAME\", \"IMAGE\"]\n",
        "\n",
        "    resp = es.search(index=index,\n",
        "                     query=query,\n",
        "                     fields=fields,\n",
        "                     size=1, # 상위 3개의 문서 가져옴\n",
        "                     sort=sort,\n",
        "                     source=False\n",
        "                     )\n",
        "    cities = []\n",
        "    explains = []\n",
        "    addresses = []\n",
        "    themes = []\n",
        "    names = []\n",
        "    images = []\n",
        "\n",
        "\n",
        "    if 'hits' in resp and 'hits' in resp['hits'] and resp['hits']['hits']:\n",
        "      for hit in resp['hits']['hits']:\n",
        "          city = hit['fields']['CITY'][0]\n",
        "          explain = hit['fields']['EXPLAIN'][0]\n",
        "          address = hit['fields']['ADDRESS'][0]\n",
        "          theme = hit['fields']['THEME'][0]\n",
        "          name = hit['fields']['NAME'][0]\n",
        "          image = hit['fields']['IMAGE'][0]\n",
        "\n",
        "          cities.append(city)\n",
        "          explains.append(explain)\n",
        "          addresses.append(address)\n",
        "          themes.append(theme)\n",
        "          names.append(name)\n",
        "          images.append(image)\n",
        "\n",
        "    return cities, explains, addresses, themes, names, images\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def truncate_text(text, max_tokens):\n",
        "    tokens = text.split()\n",
        "    if len(tokens) <= max_tokens:\n",
        "        return text\n",
        "\n",
        "    return ' '.join(tokens[:max_tokens])\n",
        "\n",
        "# Chat_gpt 답변 생성\n",
        "def chat_gpt(prompt, model=\"gpt-3.5-turbo\", max_tokens=1024, max_context_tokens=4000, safety_margin=5):\n",
        "    # Truncate the prompt content to fit within the model's context length\n",
        "    truncated_prompt = truncate_text(prompt, max_context_tokens - max_tokens - safety_margin)\n",
        "\n",
        "    response = openai.ChatCompletion.create(model=model,\n",
        "                                            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": truncated_prompt}])\n",
        "\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "st.title(\"Building GPT\")\n",
        "\n",
        "# 입력창\n",
        "with st.form(\"chat_form\"):\n",
        "    query = st.text_input(\"You: \") # 사용자에게 질문 받기\n",
        "    submit_button = st.form_submit_button(\"Send\")\n",
        "\n",
        "\n",
        "# 답변 출력\n",
        "negResponse = \"해당 질문에 관련된 폐건물정보가 없습니다.\"\n",
        "if submit_button:\n",
        "    gcity, gexplain, gaddress, gtheme, gname, gimage = search(query)\n",
        "    prompt = f\"'{query}'에 대한 답을 다음 정보를 활용해 폐건물을 추천해주세요. 사람처럼 말해주세요.: {gcity}, {gexplain}, {gaddress}, {gtheme}, {gname}\\nIf the answer is not contained in the supplied doc reply '{negResponse}' and nothing else\"\n",
        "    answer = chat_gpt(prompt)\n",
        "\n",
        "    st.write(f\"ChatGPT: {answer.strip()}\")\n",
        "\n",
        "    # 이미지 표시\n",
        "\n",
        "    st.image(gimage, use_column_width=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4iSsG7_rY1M",
        "outputId": "398fd6d4-5451-4b0c-eebc-31a288cbb84e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting elastic_gpt_app.py\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "%%writefile elastic_gpt_app.py\n",
        "\n",
        "\n",
        "import os\n",
        "import streamlit as st\n",
        "import openai\n",
        "import json\n",
        "from elasticsearch import Elasticsearch\n",
        "from urllib.parse import quote\n",
        "\n",
        "#openai apy key 입력\n",
        "openai_api = ''\n",
        "\n",
        "\n",
        "openai.api_key = openai_api\n",
        "model = \"gpt-3.5-turbo-0301\"\n",
        "\n",
        "def es_connect(cid, user, passwd):\n",
        "    es = Elasticsearch(cloud_id=cid, http_auth=(user, passwd))\n",
        "    return es\n",
        "\n",
        "# Elasticsearch Search\n",
        "def search(query_text):\n",
        "    # ES Cloud ID, Username, Password 입력\n",
        "    cid = ''\n",
        "    cu = ''\n",
        "    cp = ''\n",
        "\n",
        "    es = es_connect(cid, cu, cp)\n",
        "\n",
        "    # 엘라스틱 검색\n",
        "    query = {\n",
        "        \"bool\": {\n",
        "          \"should\": [{\n",
        "            \"match\": {\n",
        "              \"EXPLAIN\": {\n",
        "                \"query\": query_text,\n",
        "                \"boost\": 50\n",
        "              }\n",
        "            }\n",
        "          },\n",
        "          {\n",
        "          \"match_phrase_prefix\": {\n",
        "            \"EXPLAIN\": {\n",
        "              \"query\": query_text,\n",
        "              \"boost\": 1\n",
        "            }\n",
        "          }\n",
        "          }\n",
        "      ],\n",
        "      \"filter\": [{\n",
        "        \"exists\": {\n",
        "          \"field\": \"EXPLAIN\"\n",
        "          }\n",
        "      }],\n",
        "            \"minimum_should_match\": 1\n",
        "        }\n",
        "    }\n",
        "    sort={\"_score\": {\"order\": \"desc\"}}\n",
        "    index = 'old_ones'\n",
        "    fields = [\"CITY\", \"EXPLAIN\", \"ADDRESS\", \"THEME\", \"NAME\", \"IMAGE\"]\n",
        "\n",
        "    resp = es.search(index=index,\n",
        "                     query=query,\n",
        "                     fields=fields,\n",
        "                     size=1, # 상위 3개의 문서 가져옴\n",
        "                     sort=sort,\n",
        "                     source=False\n",
        "                     )\n",
        "    cities = []\n",
        "    explains = []\n",
        "    addresses = []\n",
        "    themes = []\n",
        "    names = []\n",
        "    images = []\n",
        "\n",
        "\n",
        "    if 'hits' in resp and 'hits' in resp['hits'] and resp['hits']['hits']:\n",
        "      for hit in resp['hits']['hits']:\n",
        "          city = hit['fields']['CITY'][0]\n",
        "          explain = hit['fields']['EXPLAIN'][0]\n",
        "          address = hit['fields']['ADDRESS'][0]\n",
        "          theme = hit['fields']['THEME'][0]\n",
        "          name = hit['fields']['NAME'][0]\n",
        "          image = hit['fields']['IMAGE'][0]\n",
        "\n",
        "          cities.append(city)\n",
        "          explains.append(explain)\n",
        "          addresses.append(address)\n",
        "          themes.append(theme)\n",
        "          names.append(name)\n",
        "          images.append(image)\n",
        "\n",
        "    return cities, explains, addresses, themes, names, images\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def truncate_text(text, max_tokens):\n",
        "    tokens = text.split()\n",
        "    if len(tokens) <= max_tokens:\n",
        "        return text\n",
        "\n",
        "    return ' '.join(tokens[:max_tokens])\n",
        "\n",
        "# Chat_gpt 답변 생성\n",
        "def chat_gpt(prompt, model=\"gpt-3.5-turbo\", max_tokens=1024, max_context_tokens=4000, safety_margin=5):\n",
        "    # Truncate the prompt content to fit within the model's context length\n",
        "    truncated_prompt = truncate_text(prompt, max_context_tokens - max_tokens - safety_margin)\n",
        "\n",
        "    response = openai.ChatCompletion.create(model=model,\n",
        "                                            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": truncated_prompt}])\n",
        "\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "st.title(\"Building GPT\")\n",
        "\n",
        "# 입력창\n",
        "with st.form(\"chat_form\"):\n",
        "    query = st.text_input(\"You: \") # 사용자에게 질문 받기\n",
        "    submit_button = st.form_submit_button(\"Send\")\n",
        "\n",
        "\n",
        "# 답변 출력\n",
        "negResponse = \"해당 질문에 관련된 폐건물정보가 없습니다.\"\n",
        "if submit_button:\n",
        "    gcity, gexplain, gaddress, gtheme, gname, gimage = search(query)\n",
        "    prompt = f\"'{query}'에 대한 답을 다음 정보를 활용해 폐건물을 추천해주세요. 사람처럼 말해주세요.: {gcity}, {gexplain}, {gaddress}, {gtheme}, {gname}\\nIf the answer is not contained in the supplied doc reply '{negResponse}' and nothing else\"\n",
        "    answer = chat_gpt(prompt)\n",
        "\n",
        "    # 이미지 URL\n",
        "    #escaped_url = quote(gimage, safe=':/')\n",
        "    #escaped_url = quote(gimage.encode('utf-8'), safe=':/')\n",
        "    #url = gimage[0]\n",
        "    #escaped_url = quote(url.encode('utf-8'), safe=':/')\n",
        "\n",
        "    # 이미지 표시\n",
        "    with st.container():\n",
        "      st.image(gimage, use_column_width=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6mSTjlPvqlx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rixn0GGFl4S",
        "outputId": "1ef5fa40-8031-4c63-fb7b-d1f9597ca102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting elasticsearch\n",
            "  Downloading elasticsearch-8.12.1-py3-none-any.whl (432 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m432.1/432.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting elastic-transport<9,>=8 (from elasticsearch)\n",
            "  Downloading elastic_transport-8.12.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2024.2.2)\n",
            "Installing collected packages: elastic-transport, elasticsearch\n",
            "Successfully installed elastic-transport-8.12.0 elasticsearch-8.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install elasticsearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH3et_MsKSTU"
      },
      "source": [
        "## Web UI(제대로 출력되는지 확인하는 파트)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMOyjjoHXhYf"
      },
      "outputs": [],
      "source": [
        "# Streamlit 실행\n",
        "!streamlit run /content/elastic_gpt_app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL5Az3CNHqfd"
      },
      "source": [
        "```python\n",
        "🐘\n",
        "\"\"\n",
        "UI를 콘솔이 아닌 웹에서 보기 위해 임시 페이지를 열었어요.\n",
        "아래에서 확인되는 Endpoint IP를 복사하고, npx에서 출력해주는 임시 URL에 들어가 입력해 주세요!\n",
        "\"\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KZk3RtZX43v",
        "outputId": "ef32d1fd-99e5-4deb-ae5b-3c45ab5a07c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IP Endpoint: 35.223.195.19\n"
          ]
        }
      ],
      "source": [
        "# Endpoint IP 출력\n",
        "import urllib\n",
        "print(\"IP Endpoint:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vPOznmoXkCP",
        "outputId": "26bba6c6-0b8d-4a99-95da-b3a9a7edf68d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.093s\n",
            "your url is: https://open-cars-swim.loca.lt\n"
          ]
        }
      ],
      "source": [
        "# 임시 URL 발급\n",
        "!npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gFxA5IRze1v",
        "outputId": "8a13dc87-57eb-46ce-993d-236893b6c36f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
